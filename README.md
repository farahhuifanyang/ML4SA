# ML4SA
My curated list of machine learning-based techniques for sound art in creative media.

## Audio Recognition

- Audio recognition involves the identification and classification of audio signals or specific features within audio data.

- Examples in Sound Art: Audio recognition can be used in sound art to analyze and classify sounds based on their content or characteristics. For instance, using machine learning techniques, sound artists can create installations that classify and respond to specific sound events, such as distinguishing between footsteps and bird chirping.

- State-of-the-Art Methods: Popular machine learning libraries for audio recognition include:

  - Librosa: A Python library for music and audio analysis, providing features for audio preprocessing, feature extraction, and classification.

  - Tensorflow Audio: A library that extends TensorFlow with audio-specific functionalities, including audio preprocessing, feature extraction, and model building.

  - YAMNet: A deep learning model developed by Google that can recognize a wide range of audio events from 521 audio classes.

 

## Audio Synthesis

- Audio synthesis involves the generation or creation of new audio signals using various algorithms and techniques.
- Examples in Sound Art: Sound artists can use audio synthesis to create unique and expressive sounds for their installations or compositions. They can generate abstract textures, atmospheric tones, or even imitate real-world sounds using synthesis techniques. For example, a sound artist may use granular synthesis to manipulate and transform recorded environmental sounds into a mesmerizing sonic landscape.
- State-of-the-Art Methods: Notable machine learning libraries and models for audio synthesis include:
  - Magenta: An open-source project by Google that explores the intersection of machine learning and music generation. It provides models like MusicVAE and NSynth for generating new musical compositions and timbres.
  - WaveGAN: A Generative Adversarial Network (GAN)-based model that can generate high-quality audio samples. It can learn and mimic the distribution of real audio data to create realistic and diverse sounds.

## Audio Transformation

- Audio transformation involves modifying or manipulating audio signals to achieve desired effects or transformations.
- Examples in Sound Art: Sound artists can use audio transformation techniques to alter and shape sound elements in their compositions or installations. They can apply effects like time stretching, pitch shifting, or spectral manipulation to create unique sonic experiences. For instance, a sound artist might use time stretching to slow down or stretch out a sound sample, creating an ethereal and atmospheric effect.
- State-of-the-Art Methods: Some machine learning libraries and models for audio transformation include:
  - Essentia: An open-source library for audio analysis and transformation, providing a wide range of audio processing algorithms and tools.
  - Spleeter: A library developed by Deezer that uses deep learning to perform source separation, allowing users to separate vocals, drums, and other sound sources from mixed audio.
